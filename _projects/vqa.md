---
layout: page
title: VQA
description: An approach to Video Question Answering that enhances Vision-Language Models by utilizing multiple external vision models.
img: assets/img/vqa.jpg
importance: 1
category: Research
pdf_path: /assets/pdf/VQA.pdf
---
## Project Overview

This research project introduces a groundbreaking approach to Video Question Answering (VideoQA), addressing the limitations of traditional latent video representations. Our novel method leverages multiple external vision models to transform video content into detailed natural language descriptions, significantly enhancing the capabilities of Vision-Language Models.

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <div id="pdf-container" style="width: 100%; height: 60vh; position: relative;">
            <iframe id="pdf-viewer" data-src="{{ pdf_path | relative_url }}" style="width: 100%; height: 100%; border: 1px solid #ddd; border-radius: 4px;">
            </iframe>
            <div id="pdf-resizer" style="width: 100%; height: 10px; background-color: #f0f0f0; position: absolute; bottom: -5px; cursor: ns-resize;"></div>
        </div>
    </div>
</div>
<div class="caption">
    View the full project documentation above or <a href="{{ page.pdf_path | relative_url }}" target="_blank">download the PDF</a>.
</div>

<!-- ## External Link -->

<!-- For more information, visit the [project webpage]({{ page.webpage_link }}). -->